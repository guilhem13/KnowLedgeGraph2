{"title": "Are Shortest Rationales the Best Explanations for Human Understanding?", "doi": "2203.08788v1", "authors": [{"prenom": "Hua", "nom": "Shen"}, {"prenom": "Wenbo", "nom": "Guo"}, {"prenom": "Ting-Hao 'Kenneth'", "nom": "Huang"}], "link": "http://arxiv.org/pdf/2203.08788v1", "summary": "Existing self-explaining models typically favor extracting the shortest\npossible rationales - snippets of an input text \"responsible for\" corresponding\noutput - to explain the model prediction, with the assumption that shorter\nrationales are more intuitive to humans. However, this assumption has yet to be\nvalidated. Is the shortest rationale indeed the most human-understandable? To\nanswer this question, we design a self-explaining model, LimitedInk, which\nallows users to extract rationales at any target length. Compared to existing\nbaselines, LimitedInk achieves compatible end-task performance and\nhuman-annotated rationale agreement, making it a suitable representation of the\nrecent class of self-explaining models. We use LimitedInk to conduct a user\nstudy on the impact of rationale length, where we ask human judges to predict\nthe sentiment label of documents based only on LimitedInk-generated rationales\nwith different lengths. We show rationales that are too short do not help\nhumans predict labels better than randomly masked text, suggesting the need for\nmore careful design of the best human rationales.", "date_published": "2022-03-16 17:52:07+00:00", "entities_include_in_text": ["Jain et al., 2020;\nParanjape et al., 2020", "Lei et al., 2016; Bastings et al.,\n2019", "Jain et al., 2020", "Socher et al., 2013", "Vafa et al., 2021", "Shen and Huang, 2021", "DeY-\noung et al., 2020", "Lei et al., 2016; Bastings et al., 2019; Paran-\njape et al., 2020", "Paranjape et al., 2020", "Chen et al., 2018", "Fong et al., 2019", "Jain et al., 2020; Bast-\nings et al., 2019", "DeYoung\net al., 2020", "Lei et al., 2016; Bastings et al., 2019", "Jain et al., 2020", "Paran-\njape et al., 2020", "DeYoung et al., 2020", "Likert, 1932", "Jain\net al., 2020; Paranjape et al., 2020", "Rajagopal et al., 2021", "Yu et al., 2019; Bastings et al., 2019; Jain\net al., 2020). Paranjape et al. (2020", "Carton et al., 2020; Paranjape et al., 2020", "Ribeiro et al., 2016", "Lertvittayakumjorn and Toni, 2019; Shen\nand Huang, 2020", "Chuang et al., 2021", "WOAH 2021", "Jang et al., 2017", "Fong\net al., 2019", "Lei et al., 2016; Bastings et al., 2019", "Chang et al.,\n2020; Jain et al., 2020", "Paranjape et al., 2020"], "entities_from_reference": [{"prenom": "Christopher D.", "nom": "Manning"}, {"prenom": "Byron C.", "nom": "Wallace"}, {"prenom": "Martin J.", "nom": "Wainwright"}, {"prenom": "Michael I.", "nom": "Jordan"}, {"prenom": "Bhargavi", "nom": "Paranjape"}, {"prenom": "Hannaneh", "nom": "Hajishirzi"}, {"prenom": "John", "nom": "Thickstun"}, {"prenom": "Luke", "nom": "Zettlemoyer"}, {"prenom": "Mandar", "nom": "Joshi"}, {"prenom": "Shiyu", "nom": "Chang"}, {"prenom": "Yuntian", "nom": "Deng"}, {"prenom": "Tommi", "nom": "Jaakkola"}, {"prenom": "Yang", "nom": "Zhang"}, {"prenom": "Keyon", "nom": "Vafa"}, {"prenom": "Alexander", "nom": "Rush"}, {"prenom": "David", "nom": "Blei"}, {"prenom": "Anirudh", "nom": "Rathore"}, {"prenom": "Chenhao", "nom": "Tan"}, {"prenom": "Ruth", "nom": "Fong"}, {"prenom": "Mandela", "nom": "Patrick"}, {"prenom": "Regina", "nom": "Barzilay"}, {"prenom": "Carlos", "nom": "Guestrin"}, {"prenom": "Tulio", "nom": "Ribeiro"}, {"prenom": "Samuel", "nom": "Carton"}, {"prenom": "Ivan", "nom": "Titov"}, {"prenom": "Ben", "nom": "Poole"}, {"prenom": "Wilker", "nom": "Aziz"}, {"prenom": "Eric", "nom": "Jang"}, {"prenom": "Sameer", "nom": "Singh"}, {"prenom": "Jasmijn", "nom": "Bastings"}, {"prenom": "Andrea", "nom": "Vedaldi"}, {"prenom": "Tao", "nom": "Lei"}, {"prenom": "Mingye", "nom": "Gao"}, {"prenom": "No firstname", "nom": "Wilker"}, {"prenom": "Omar", "nom": "Zaidan"}, {"prenom": "Worker", "nom": "Group"}, {"prenom": "Jianbo", "nom": "Chen"}, {"prenom": "Richard", "nom": "Socher"}, {"prenom": "Jason", "nom": "Eisner"}, {"prenom": "No firstname", "nom": "Huang"}, {"prenom": "Tommi", "nom": "S."}, {"prenom": "No firstname", "nom": "Chuang"}, {"prenom": "Jason", "nom": "Chuang"}, {"prenom": "Michael I.", "nom": "Jordan."}, {"prenom": "No firstname", "nom": "Stockholm"}, {"prenom": "Luke", "nom": "Zettlemoyer."}, {"prenom": "Virtual", "nom": "Event"}, {"prenom": "No firstname", "nom": "Annual"}, {"prenom": "Shixiang", "nom": "Gu"}, {"prenom": "Vidhisha", "nom": "Balachandran"}, {"prenom": "Random Baselines", "nom": "Human"}, {"prenom": "James", "nom": "Glass"}, {"prenom": "Jean", "nom": "Wu"}, {"prenom": "Model", "nom": "Components"}, {"prenom": "Alex", "nom": "Perelygin"}, {"prenom": "No firstname", "nom": "Hannaneh"}, {"prenom": "Yulia", "nom": "Tsvetkov"}, {"prenom": "Subset Sampling", "nom": "Process"}, {"prenom": "Caiming", "nom": "Xiong"}, {"prenom": "No firstname", "nom": "Lee"}, {"prenom": "Eduard H", "nom": "Hovy"}, {"prenom": "Human", "nom": "Computation"}, {"prenom": "Jay", "nom": "DeYoung"}, {"prenom": "Sparse", "nom": "IB"}, {"prenom": "Data", "nom": "Mining"}, {"prenom": "Andrew", "nom": "Ng"}, {"prenom": "Norm", "nom": "Minimization"}, {"prenom": "Setups No Sufficiency No Continuity No Sparsity", "nom": "No"}, {"prenom": "Details", "nom": "Training"}, {"prenom": "Nazneen Fatema", "nom": "Rajani"}, {"prenom": "Andrea", "nom": "Vedaldi."}, {"prenom": "Francesca", "nom": "Toni."}, {"prenom": "Yulia", "nom": "Tsvetkov."}, {"prenom": "Dheeraj", "nom": "Rajagopal"}, {"prenom": "Eric", "nom": "Lehman"}, {"prenom": "Sarthak", "nom": "Jain"}, {"prenom": "Jason", "nom": "Eisner."}, {"prenom": "Christopher", "nom": "Potts."}, {"prenom": "User", "nom": "Interface"}, {"prenom": "Ben", "nom": "Poole."}, {"prenom": "Hongyin", "nom": "Luo"}, {"prenom": "Ivan", "nom": "Titov."}, {"prenom": "Rensis", "nom": "Likert"}, {"prenom": "Francesca", "nom": "Toni"}, {"prenom": "No firstname", "nom": "Jain"}, {"prenom": "Yuval", "nom": "Pinter"}, {"prenom": "Tao", "nom": "Lei"}, {"prenom": "Le", "nom": "Song"}, {"prenom": "Byron C.", "nom": "Wallace."}, {"prenom": "Punta", "nom": "Cana"}, {"prenom": "Movie", "nom": "Review"}, {"prenom": "Piyawat", "nom": "Lertvittayakumjorn"}, {"prenom": "No firstname", "nom": "Model"}, {"prenom": "Sarah", "nom": "Wiegreffe"}, {"prenom": "Hua", "nom": "Shen"}, {"prenom": "Online", "nom": "Abuse"}, {"prenom": "Mo", "nom": "Yu"}, {"prenom": "Christopher", "nom": "Potts"}, {"prenom": "Worker Study", "nom": "Interface"}], "url_in_text": ["washington.edu", "https://github.com/", "OpenReview.net"], "doi_in_text": []}{"title": "Are Shortest Rationales the Best Explanations for Human Understanding?", "doi": "2203.08788v1", "authors": [{"prenom": "Hua", "nom": "Shen"}, {"prenom": "Wenbo", "nom": "Guo"}, {"prenom": "Ting-Hao 'Kenneth'", "nom": "Huang"}], "link": "http://arxiv.org/pdf/2203.08788v1", "summary": "Existing self-explaining models typically favor extracting the shortest\npossible rationales - snippets of an input text \"responsible for\" corresponding\noutput - to explain the model prediction, with the assumption that shorter\nrationales are more intuitive to humans. However, this assumption has yet to be\nvalidated. Is the shortest rationale indeed the most human-understandable? To\nanswer this question, we design a self-explaining model, LimitedInk, which\nallows users to extract rationales at any target length. Compared to existing\nbaselines, LimitedInk achieves compatible end-task performance and\nhuman-annotated rationale agreement, making it a suitable representation of the\nrecent class of self-explaining models. We use LimitedInk to conduct a user\nstudy on the impact of rationale length, where we ask human judges to predict\nthe sentiment label of documents based only on LimitedInk-generated rationales\nwith different lengths. We show rationales that are too short do not help\nhumans predict labels better than randomly masked text, suggesting the need for\nmore careful design of the best human rationales.", "date_published": "2022-03-16 17:52:07+00:00", "entities_include_in_text": ["Jain et al., 2020;\nParanjape et al., 2020", "Lei et al., 2016; Bastings et al.,\n2019", "Jain et al., 2020", "Socher et al., 2013", "Vafa et al., 2021", "Shen and Huang, 2021", "DeY-\noung et al., 2020", "Lei et al., 2016; Bastings et al., 2019; Paran-\njape et al., 2020", "Paranjape et al., 2020", "Chen et al., 2018", "Fong et al., 2019", "Jain et al., 2020; Bast-\nings et al., 2019", "DeYoung\net al., 2020", "Lei et al., 2016; Bastings et al., 2019", "Jain et al., 2020", "Paran-\njape et al., 2020", "DeYoung et al., 2020", "Likert, 1932", "Jain\net al., 2020; Paranjape et al., 2020", "Rajagopal et al., 2021", "Yu et al., 2019; Bastings et al., 2019; Jain\net al., 2020). Paranjape et al. (2020", "Carton et al., 2020; Paranjape et al., 2020", "Ribeiro et al., 2016", "Lertvittayakumjorn and Toni, 2019; Shen\nand Huang, 2020", "Chuang et al., 2021", "WOAH 2021", "Jang et al., 2017", "Fong\net al., 2019", "Lei et al., 2016; Bastings et al., 2019", "Chang et al.,\n2020; Jain et al., 2020", "Paranjape et al., 2020"], "entities_from_reference": [{"prenom": "Michael I.", "nom": "Jordan"}, {"prenom": "Martin J.", "nom": "Wainwright"}, {"prenom": "Christopher D.", "nom": "Manning"}, {"prenom": "Byron C.", "nom": "Wallace"}, {"prenom": "Hannaneh", "nom": "Hajishirzi"}, {"prenom": "Mandar", "nom": "Joshi"}, {"prenom": "Bhargavi", "nom": "Paranjape"}, {"prenom": "John", "nom": "Thickstun"}, {"prenom": "Luke", "nom": "Zettlemoyer"}, {"prenom": "Keyon", "nom": "Vafa"}, {"prenom": "Alexander", "nom": "Rush"}, {"prenom": "David", "nom": "Blei"}, {"prenom": "Yang", "nom": "Zhang"}, {"prenom": "Shiyu", "nom": "Chang"}, {"prenom": "Yuntian", "nom": "Deng"}, {"prenom": "Tommi", "nom": "Jaakkola"}, {"prenom": "Anirudh", "nom": "Rathore"}, {"prenom": "Sameer", "nom": "Singh"}, {"prenom": "Tao", "nom": "Lei"}, {"prenom": "Eric", "nom": "Jang"}, {"prenom": "Ivan", "nom": "Titov"}, {"prenom": "Samuel", "nom": "Carton"}, {"prenom": "Carlos", "nom": "Guestrin"}, {"prenom": "Wilker", "nom": "Aziz"}, {"prenom": "Mandela", "nom": "Patrick"}, {"prenom": "Tulio", "nom": "Ribeiro"}, {"prenom": "Ruth", "nom": "Fong"}, {"prenom": "Chenhao", "nom": "Tan"}, {"prenom": "Regina", "nom": "Barzilay"}, {"prenom": "Ben", "nom": "Poole"}, {"prenom": "Andrea", "nom": "Vedaldi"}, {"prenom": "Jasmijn", "nom": "Bastings"}, {"prenom": "Yuval", "nom": "Pinter"}, {"prenom": "Sarah", "nom": "Wiegreffe"}, {"prenom": "No firstname", "nom": "Wilker"}, {"prenom": "Jason", "nom": "Chuang"}, {"prenom": "Sparse", "nom": "IB"}, {"prenom": "Subset Sampling", "nom": "Process"}, {"prenom": "James", "nom": "Glass"}, {"prenom": "No firstname", "nom": "Lee"}, {"prenom": "Nazneen Fatema", "nom": "Rajani"}, {"prenom": "Yulia", "nom": "Tsvetkov"}, {"prenom": "Dheeraj", "nom": "Rajagopal"}, {"prenom": "Ivan", "nom": "Titov."}, {"prenom": "Setups No Sufficiency No Continuity No Sparsity", "nom": "No"}, {"prenom": "Norm", "nom": "Minimization"}, {"prenom": "Worker Study", "nom": "Interface"}, {"prenom": "Jason", "nom": "Eisner"}, {"prenom": "No firstname", "nom": "Stockholm"}, {"prenom": "Le", "nom": "Song"}, {"prenom": "Byron C.", "nom": "Wallace."}, {"prenom": "Details", "nom": "Training"}, {"prenom": "User", "nom": "Interface"}, {"prenom": "Jianbo", "nom": "Chen"}, {"prenom": "Mingye", "nom": "Gao"}, {"prenom": "Jasmijn", "nom": "Bastings"}, {"prenom": "Piyawat", "nom": "Lertvittayakumjorn"}, {"prenom": "Francesca", "nom": "Toni."}, {"prenom": "Virtual", "nom": "Event"}, {"prenom": "Michael I.", "nom": "Jordan."}, {"prenom": "Mo", "nom": "Yu"}, {"prenom": "Human", "nom": "Computation"}, {"prenom": "Sarthak", "nom": "Jain"}, {"prenom": "Caiming", "nom": "Xiong"}, {"prenom": "Tommi", "nom": "S."}, {"prenom": "Jay", "nom": "DeYoung"}, {"prenom": "Jean", "nom": "Wu"}, {"prenom": "Punta", "nom": "Cana"}, {"prenom": "Shixiang", "nom": "Gu"}, {"prenom": "Hua", "nom": "Shen"}, {"prenom": "Yulia", "nom": "Tsvetkov."}, {"prenom": "Christopher", "nom": "Potts"}, {"prenom": "Jason", "nom": "Eisner."}, {"prenom": "Random Baselines", "nom": "Human"}, {"prenom": "No firstname", "nom": "Hannaneh"}, {"prenom": "Andrea", "nom": "Vedaldi."}, {"prenom": "Luke", "nom": "Zettlemoyer."}, {"prenom": "Online", "nom": "Abuse"}, {"prenom": "Ben", "nom": "Poole."}, {"prenom": "Eduard H", "nom": "Hovy"}, {"prenom": "Christopher", "nom": "Potts."}, {"prenom": "No firstname", "nom": "Jain"}, {"prenom": "Rensis", "nom": "Likert"}, {"prenom": "Omar", "nom": "Zaidan"}, {"prenom": "Richard", "nom": "Socher"}, {"prenom": "No firstname", "nom": "Model"}, {"prenom": "No firstname", "nom": "Annual"}, {"prenom": "Eric", "nom": "Lehman"}, {"prenom": "Alex", "nom": "Perelygin"}, {"prenom": "No firstname", "nom": "Huang"}, {"prenom": "Andrew", "nom": "Ng"}, {"prenom": "Hongyin", "nom": "Luo"}, {"prenom": "Worker", "nom": "Group"}, {"prenom": "Model", "nom": "Components"}, {"prenom": "Francesca", "nom": "Toni"}, {"prenom": "Vidhisha", "nom": "Balachandran"}, {"prenom": "No firstname", "nom": "Chuang"}, {"prenom": "Data", "nom": "Mining"}, {"prenom": "Movie", "nom": "Review"}], "url_in_text": ["washington.edu", "https://github.com/", "OpenReview.net"], "doi_in_text": []}{"title": "Are Shortest Rationales the Best Explanations for Human Understanding?", "doi": "2203.08788v1", "authors": [{"prenom": "Hua", "nom": "Shen"}, {"prenom": "Wenbo", "nom": "Guo"}, {"prenom": "Ting-Hao 'Kenneth'", "nom": "Huang"}], "link": "http://arxiv.org/pdf/2203.08788v1", "summary": "Existing self-explaining models typically favor extracting the shortest\npossible rationales - snippets of an input text \"responsible for\" corresponding\noutput - to explain the model prediction, with the assumption that shorter\nrationales are more intuitive to humans. However, this assumption has yet to be\nvalidated. Is the shortest rationale indeed the most human-understandable? To\nanswer this question, we design a self-explaining model, LimitedInk, which\nallows users to extract rationales at any target length. Compared to existing\nbaselines, LimitedInk achieves compatible end-task performance and\nhuman-annotated rationale agreement, making it a suitable representation of the\nrecent class of self-explaining models. We use LimitedInk to conduct a user\nstudy on the impact of rationale length, where we ask human judges to predict\nthe sentiment label of documents based only on LimitedInk-generated rationales\nwith different lengths. We show rationales that are too short do not help\nhumans predict labels better than randomly masked text, suggesting the need for\nmore careful design of the best human rationales.", "date_published": "2022-03-16 17:52:07+00:00", "entities_include_in_text": ["Jain et al., 2020;\nParanjape et al., 2020", "Lei et al., 2016; Bastings et al.,\n2019", "Jain et al., 2020", "Socher et al., 2013", "Vafa et al., 2021", "Shen and Huang, 2021", "DeY-\noung et al., 2020", "Lei et al., 2016; Bastings et al., 2019; Paran-\njape et al., 2020", "Paranjape et al., 2020", "Chen et al., 2018", "Fong et al., 2019", "Jain et al., 2020; Bast-\nings et al., 2019", "DeYoung\net al., 2020", "Lei et al., 2016; Bastings et al., 2019", "Jain et al., 2020", "Paran-\njape et al., 2020", "DeYoung et al., 2020", "Likert, 1932", "Jain\net al., 2020; Paranjape et al., 2020", "Rajagopal et al., 2021", "Yu et al., 2019; Bastings et al., 2019; Jain\net al., 2020). Paranjape et al. (2020", "Carton et al., 2020; Paranjape et al., 2020", "Ribeiro et al., 2016", "Lertvittayakumjorn and Toni, 2019; Shen\nand Huang, 2020", "Chuang et al., 2021", "WOAH 2021", "Jang et al., 2017", "Fong\net al., 2019", "Lei et al., 2016; Bastings et al., 2019", "Chang et al.,\n2020; Jain et al., 2020", "Paranjape et al., 2020"], "entities_from_reference": [{"prenom": "Martin J.", "nom": "Wainwright"}, {"prenom": "Christopher D.", "nom": "Manning"}, {"prenom": "Michael I.", "nom": "Jordan"}, {"prenom": "Byron C.", "nom": "Wallace"}, {"prenom": "John", "nom": "Thickstun"}, {"prenom": "Luke", "nom": "Zettlemoyer"}, {"prenom": "Mandar", "nom": "Joshi"}, {"prenom": "Hannaneh", "nom": "Hajishirzi"}, {"prenom": "Bhargavi", "nom": "Paranjape"}, {"prenom": "Yang", "nom": "Zhang"}, {"prenom": "Shiyu", "nom": "Chang"}, {"prenom": "David", "nom": "Blei"}, {"prenom": "Yuntian", "nom": "Deng"}, {"prenom": "Alexander", "nom": "Rush"}, {"prenom": "Tommi", "nom": "Jaakkola"}, {"prenom": "Keyon", "nom": "Vafa"}, {"prenom": "Anirudh", "nom": "Rathore"}, {"prenom": "Tulio", "nom": "Ribeiro"}, {"prenom": "Carlos", "nom": "Guestrin"}, {"prenom": "Regina", "nom": "Barzilay"}, {"prenom": "Ruth", "nom": "Fong"}, {"prenom": "Tao", "nom": "Lei"}, {"prenom": "Ben", "nom": "Poole"}, {"prenom": "Eric", "nom": "Jang"}, {"prenom": "Andrea", "nom": "Vedaldi"}, {"prenom": "Samuel", "nom": "Carton"}, {"prenom": "Ivan", "nom": "Titov"}, {"prenom": "Wilker", "nom": "Aziz"}, {"prenom": "Jasmijn", "nom": "Bastings"}, {"prenom": "Sameer", "nom": "Singh"}, {"prenom": "Chenhao", "nom": "Tan"}, {"prenom": "Mandela", "nom": "Patrick"}, {"prenom": "Sarah", "nom": "Wiegreffe"}, {"prenom": "Worker Study", "nom": "Interface"}, {"prenom": "No firstname", "nom": "Wilker"}, {"prenom": "Human", "nom": "Computation"}, {"prenom": "Eduard H", "nom": "Hovy"}, {"prenom": "Jean", "nom": "Wu"}, {"prenom": "Francesca", "nom": "Toni."}, {"prenom": "Sarthak", "nom": "Jain"}, {"prenom": "Christopher", "nom": "Potts"}, {"prenom": "Ben", "nom": "Poole."}, {"prenom": "Sparse", "nom": "IB"}, {"prenom": "Ivan", "nom": "Titov."}, {"prenom": "No firstname", "nom": "Annual"}, {"prenom": "Rensis", "nom": "Likert"}, {"prenom": "Worker", "nom": "Group"}, {"prenom": "Norm", "nom": "Minimization"}, {"prenom": "No firstname", "nom": "Hannaneh"}, {"prenom": "Yulia", "nom": "Tsvetkov"}, {"prenom": "Shixiang", "nom": "Gu"}, {"prenom": "Jason", "nom": "Eisner."}, {"prenom": "Andrew", "nom": "Ng"}, {"prenom": "Michael I.", "nom": "Jordan."}, {"prenom": "Mandela", "nom": "Patrick"}, {"prenom": "Nazneen Fatema", "nom": "Rajani"}, {"prenom": "No firstname", "nom": "Jain"}, {"prenom": "Vidhisha", "nom": "Balachandran"}, {"prenom": "Jay", "nom": "DeYoung"}, {"prenom": "Virtual", "nom": "Event"}, {"prenom": "No firstname", "nom": "Model"}, {"prenom": "Tommi", "nom": "S."}, {"prenom": "No firstname", "nom": "Chuang"}, {"prenom": "Random Baselines", "nom": "Human"}, {"prenom": "Le", "nom": "Song"}, {"prenom": "Model", "nom": "Components"}, {"prenom": "Jianbo", "nom": "Chen"}, {"prenom": "Jason", "nom": "Chuang"}, {"prenom": "Setups No Sufficiency No Continuity No Sparsity", "nom": "No"}, {"prenom": "Eric", "nom": "Lehman"}, {"prenom": "Richard", "nom": "Socher"}, {"prenom": "Byron C.", "nom": "Wallace."}, {"prenom": "Caiming", "nom": "Xiong"}, {"prenom": "Andrea", "nom": "Vedaldi."}, {"prenom": "Francesca", "nom": "Toni"}, {"prenom": "Dheeraj", "nom": "Rajagopal"}, {"prenom": "No firstname", "nom": "Lee"}, {"prenom": "Mo", "nom": "Yu"}, {"prenom": "Piyawat", "nom": "Lertvittayakumjorn"}, {"prenom": "Christopher", "nom": "Potts."}, {"prenom": "User", "nom": "Interface"}, {"prenom": "Mingye", "nom": "Gao"}, {"prenom": "Online", "nom": "Abuse"}, {"prenom": "Hua", "nom": "Shen"}, {"prenom": "Yulia", "nom": "Tsvetkov."}, {"prenom": "Details", "nom": "Training"}, {"prenom": "Hongyin", "nom": "Luo"}, {"prenom": "Punta", "nom": "Cana"}, {"prenom": "Subset Sampling", "nom": "Process"}, {"prenom": "Jason", "nom": "Eisner"}, {"prenom": "Yuval", "nom": "Pinter"}, {"prenom": "James", "nom": "Glass"}, {"prenom": "Data", "nom": "Mining"}, {"prenom": "Luke", "nom": "Zettlemoyer."}, {"prenom": "Movie", "nom": "Review"}, {"prenom": "No firstname", "nom": "Huang"}, {"prenom": "Omar", "nom": "Zaidan"}, {"prenom": "No firstname", "nom": "Stockholm"}, {"prenom": "Alex", "nom": "Perelygin"}], "url_in_text": ["washington.edu", "https://github.com/", "OpenReview.net"], "doi_in_text": []}{"title": "Are Shortest Rationales the Best Explanations for Human Understanding?", "doi": "2203.08788v1", "authors": [{"prenom": "Hua", "nom": "Shen", "name": "SH"}, {"prenom": "Wenbo", "nom": "Guo", "name": "GW"}, {"prenom": "Ting-Hao 'Kenneth'", "nom": "Huang", "name": "HT"}], "link": "http://arxiv.org/pdf/2203.08788v1", "summary": "Existing self-explaining models typically favor extracting the shortest\npossible rationales - snippets of an input text \"responsible for\" corresponding\noutput - to explain the model prediction, with the assumption that shorter\nrationales are more intuitive to humans. However, this assumption has yet to be\nvalidated. Is the shortest rationale indeed the most human-understandable? To\nanswer this question, we design a self-explaining model, LimitedInk, which\nallows users to extract rationales at any target length. Compared to existing\nbaselines, LimitedInk achieves compatible end-task performance and\nhuman-annotated rationale agreement, making it a suitable representation of the\nrecent class of self-explaining models. We use LimitedInk to conduct a user\nstudy on the impact of rationale length, where we ask human judges to predict\nthe sentiment label of documents based only on LimitedInk-generated rationales\nwith different lengths. We show rationales that are too short do not help\nhumans predict labels better than randomly masked text, suggesting the need for\nmore careful design of the best human rationales.", "date_published": "2022-03-16 17:52:07+00:00", "entities_include_in_text": ["Jain et al., 2020;\nParanjape et al., 2020", "Lei et al., 2016; Bastings et al.,\n2019", "Jain et al., 2020", "Socher et al., 2013", "Vafa et al., 2021", "Shen and Huang, 2021", "DeY-\noung et al., 2020", "Lei et al., 2016; Bastings et al., 2019; Paran-\njape et al., 2020", "Paranjape et al., 2020", "Chen et al., 2018", "Fong et al., 2019", "Jain et al., 2020; Bast-\nings et al., 2019", "DeYoung\net al., 2020", "Lei et al., 2016; Bastings et al., 2019", "Jain et al., 2020", "Paran-\njape et al., 2020", "DeYoung et al., 2020", "Likert, 1932", "Jain\net al., 2020; Paranjape et al., 2020", "Rajagopal et al., 2021", "Yu et al., 2019; Bastings et al., 2019; Jain\net al., 2020). Paranjape et al. (2020", "Carton et al., 2020; Paranjape et al., 2020", "Ribeiro et al., 2016", "Lertvittayakumjorn and Toni, 2019; Shen\nand Huang, 2020", "Chuang et al., 2021", "WOAH 2021", "Jang et al., 2017", "Fong\net al., 2019", "Lei et al., 2016; Bastings et al., 2019", "Chang et al.,\n2020; Jain et al., 2020", "Paranjape et al., 2020"], "entities_from_reference": [{"prenom": "Christopher D.", "nom": "Manning", "name": "MC"}, {"prenom": "Byron C.", "nom": "Wallace", "name": "WB"}, {"prenom": "Michael I.", "nom": "Jordan", "name": "JM"}, {"prenom": "Martin J.", "nom": "Wainwright", "name": "WM"}, {"prenom": "Luke", "nom": "Zettlemoyer", "name": "ZL"}, {"prenom": "Mandar", "nom": "Joshi", "name": "JM"}, {"prenom": "Hannaneh", "nom": "Hajishirzi", "name": "HH"}, {"prenom": "Bhargavi", "nom": "Paranjape", "name": "PB"}, {"prenom": "John", "nom": "Thickstun", "name": "TJ"}, {"prenom": "Tommi", "nom": "Jaakkola", "name": "JT"}, {"prenom": "David", "nom": "Blei", "name": "BD"}, {"prenom": "Shiyu", "nom": "Chang", "name": "CS"}, {"prenom": "Yuntian", "nom": "Deng", "name": "DY"}, {"prenom": "Keyon", "nom": "Vafa", "name": "VK"}, {"prenom": "Yang", "nom": "Zhang", "name": "ZY"}, {"prenom": "Alexander", "nom": "Rush", "name": "RA"}, {"prenom": "Anirudh", "nom": "Rathore", "name": "RA"}, {"prenom": "Sameer", "nom": "Singh", "name": "SS"}, {"prenom": "Regina", "nom": "Barzilay", "name": "BR"}, {"prenom": "Ivan", "nom": "Titov", "name": "TI"}, {"prenom": "Eric", "nom": "Jang", "name": "JE"}, {"prenom": "Samuel", "nom": "Carton", "name": "CS"}, {"prenom": "Andrea", "nom": "Vedaldi", "name": "VA"}, {"prenom": "Ben", "nom": "Poole", "name": "PB"}, {"prenom": "Tulio", "nom": "Ribeiro", "name": "RT"}, {"prenom": "Carlos", "nom": "Guestrin", "name": "GC"}, {"prenom": "Chenhao", "nom": "Tan", "name": "TC"}, {"prenom": "Tao", "nom": "Lei", "name": "LT"}, {"prenom": "Mandela", "nom": "Patrick", "name": "PM"}, {"prenom": "Wilker", "nom": "Aziz", "name": "AW"}, {"prenom": "Jasmijn", "nom": "Bastings", "name": "BJ"}, {"prenom": "Ruth", "nom": "Fong", "name": "FR"}, {"prenom": "Eduard H", "nom": "Hovy"}, {"prenom": "Human", "nom": "Computation"}, {"prenom": "Hongyin", "nom": "Luo"}, {"prenom": "No firstname", "nom": "Stockholm"}, {"prenom": "Yulia", "nom": "Tsvetkov."}, {"prenom": "No firstname", "nom": "Chuang"}, {"prenom": "Dheeraj", "nom": "Rajagopal"}, {"prenom": "Shixiang", "nom": "Gu"}, {"prenom": "Ruth", "nom": "Fong"}, {"prenom": "Christopher", "nom": "Potts"}, {"prenom": "Ben", "nom": "Poole."}, {"prenom": "Setups No Sufficiency No Continuity No Sparsity", "nom": "No"}, {"prenom": "Punta", "nom": "Cana"}, {"prenom": "No firstname", "nom": "Model"}, {"prenom": "No firstname", "nom": "Wilker"}, {"prenom": "No firstname", "nom": "Jain"}, {"prenom": "Rensis", "nom": "Likert"}, {"prenom": "Jianbo", "nom": "Chen"}, {"prenom": "Tommi", "nom": "S."}, {"prenom": "Online", "nom": "Abuse"}, {"prenom": "Worker", "nom": "Group"}, {"prenom": "Sarthak", "nom": "Jain"}, {"prenom": "Yuval", "nom": "Pinter"}, {"prenom": "Caiming", "nom": "Xiong"}, {"prenom": "No firstname", "nom": "Huang"}, {"prenom": "Jean", "nom": "Wu"}, {"prenom": "Sarah", "nom": "Wiegreffe"}, {"prenom": "Random Baselines", "nom": "Human"}, {"prenom": "Byron C.", "nom": "Wallace."}, {"prenom": "Sparse", "nom": "IB"}, {"prenom": "Worker Study", "nom": "Interface"}, {"prenom": "Omar", "nom": "Zaidan"}, {"prenom": "Michael I.", "nom": "Jordan."}, {"prenom": "Luke", "nom": "Zettlemoyer."}, {"prenom": "Movie", "nom": "Review"}, {"prenom": "Yulia", "nom": "Tsvetkov"}, {"prenom": "Mo", "nom": "Yu"}, {"prenom": "James", "nom": "Glass"}, {"prenom": "Jay", "nom": "DeYoung"}, {"prenom": "Subset Sampling", "nom": "Process"}, {"prenom": "Christopher", "nom": "Potts."}, {"prenom": "Richard", "nom": "Socher"}, {"prenom": "Eric", "nom": "Lehman"}, {"prenom": "Andrea", "nom": "Vedaldi."}, {"prenom": "No firstname", "nom": "Hannaneh"}, {"prenom": "Andrew", "nom": "Ng"}, {"prenom": "Data", "nom": "Mining"}, {"prenom": "Le", "nom": "Song"}, {"prenom": "Piyawat", "nom": "Lertvittayakumjorn"}, {"prenom": "Details", "nom": "Training"}, {"prenom": "No firstname", "nom": "Annual"}, {"prenom": "Mingye", "nom": "Gao"}, {"prenom": "Alex", "nom": "Perelygin"}, {"prenom": "Virtual", "nom": "Event"}, {"prenom": "Jason", "nom": "Chuang"}, {"prenom": "Vidhisha", "nom": "Balachandran"}, {"prenom": "Ivan", "nom": "Titov."}, {"prenom": "Jason", "nom": "Eisner"}, {"prenom": "Hua", "nom": "Shen"}, {"prenom": "Jason", "nom": "Eisner."}, {"prenom": "User", "nom": "Interface"}, {"prenom": "Francesca", "nom": "Toni."}, {"prenom": "Nazneen Fatema", "nom": "Rajani"}, {"prenom": "No firstname", "nom": "Lee"}, {"prenom": "Francesca", "nom": "Toni"}, {"prenom": "Norm", "nom": "Minimization"}, {"prenom": "Model", "nom": "Components"}], "url_in_text": ["washington.edu", "https://github.com/", "OpenReview.net"], "doi_in_text": []}{"title": "Are Shortest Rationales the Best Explanations for Human Understanding?", "doi": "2203.08788v1", "authors": [{"prenom": "Hua", "nom": "Shen", "name": "ShenHua"}, {"prenom": "Wenbo", "nom": "Guo", "name": "GuoWenbo"}, {"prenom": "Ting-Hao 'Kenneth'", "nom": "Huang", "name": "HuangTing-Hao 'Kenneth'"}], "link": "http://arxiv.org/pdf/2203.08788v1", "summary": "Existing self-explaining models typically favor extracting the shortest\npossible rationales - snippets of an input text \"responsible for\" corresponding\noutput - to explain the model prediction, with the assumption that shorter\nrationales are more intuitive to humans. However, this assumption has yet to be\nvalidated. Is the shortest rationale indeed the most human-understandable? To\nanswer this question, we design a self-explaining model, LimitedInk, which\nallows users to extract rationales at any target length. Compared to existing\nbaselines, LimitedInk achieves compatible end-task performance and\nhuman-annotated rationale agreement, making it a suitable representation of the\nrecent class of self-explaining models. We use LimitedInk to conduct a user\nstudy on the impact of rationale length, where we ask human judges to predict\nthe sentiment label of documents based only on LimitedInk-generated rationales\nwith different lengths. We show rationales that are too short do not help\nhumans predict labels better than randomly masked text, suggesting the need for\nmore careful design of the best human rationales.", "date_published": "2022-03-16 17:52:07+00:00", "entities_include_in_text": ["Jain et al., 2020;\nParanjape et al., 2020", "Lei et al., 2016; Bastings et al.,\n2019", "Jain et al., 2020", "Socher et al., 2013", "Vafa et al., 2021", "Shen and Huang, 2021", "DeY-\noung et al., 2020", "Lei et al., 2016; Bastings et al., 2019; Paran-\njape et al., 2020", "Paranjape et al., 2020", "Chen et al., 2018", "Fong et al., 2019", "Jain et al., 2020; Bast-\nings et al., 2019", "DeYoung\net al., 2020", "Lei et al., 2016; Bastings et al., 2019", "Jain et al., 2020", "Paran-\njape et al., 2020", "DeYoung et al., 2020", "Likert, 1932", "Jain\net al., 2020; Paranjape et al., 2020", "Rajagopal et al., 2021", "Yu et al., 2019; Bastings et al., 2019; Jain\net al., 2020). Paranjape et al. (2020", "Carton et al., 2020; Paranjape et al., 2020", "Ribeiro et al., 2016", "Lertvittayakumjorn and Toni, 2019; Shen\nand Huang, 2020", "Chuang et al., 2021", "WOAH 2021", "Jang et al., 2017", "Fong\net al., 2019", "Lei et al., 2016; Bastings et al., 2019", "Chang et al.,\n2020; Jain et al., 2020", "Paranjape et al., 2020"], "entities_from_reference": [{"prenom": "Byron C.", "nom": "Wallace", "name": "WallaceByron C."}, {"prenom": "Martin J.", "nom": "Wainwright", "name": "WainwrightMartin J."}, {"prenom": "Christopher D.", "nom": "Manning", "name": "ManningChristopher D."}, {"prenom": "Michael I.", "nom": "Jordan", "name": "JordanMichael I."}, {"prenom": "Mandar", "nom": "Joshi", "name": "JoshiMandar"}, {"prenom": "Hannaneh", "nom": "Hajishirzi", "name": "HajishirziHannaneh"}, {"prenom": "Luke", "nom": "Zettlemoyer", "name": "ZettlemoyerLuke"}, {"prenom": "John", "nom": "Thickstun", "name": "ThickstunJohn"}, {"prenom": "Bhargavi", "nom": "Paranjape", "name": "ParanjapeBhargavi"}, {"prenom": "Tommi", "nom": "Jaakkola", "name": "JaakkolaTommi"}, {"prenom": "Keyon", "nom": "Vafa", "name": "VafaKeyon"}, {"prenom": "Yuntian", "nom": "Deng", "name": "DengYuntian"}, {"prenom": "Shiyu", "nom": "Chang", "name": "ChangShiyu"}, {"prenom": "Alexander", "nom": "Rush", "name": "RushAlexander"}, {"prenom": "Yang", "nom": "Zhang", "name": "ZhangYang"}, {"prenom": "David", "nom": "Blei", "name": "BleiDavid"}, {"prenom": "Chenhao", "nom": "Tan", "name": "TanChenhao"}, {"prenom": "Andrea", "nom": "Vedaldi", "name": "VedaldiAndrea"}, {"prenom": "Tao", "nom": "Lei", "name": "LeiTao"}, {"prenom": "Carlos", "nom": "Guestrin", "name": "GuestrinCarlos"}, {"prenom": "Ruth", "nom": "Fong", "name": "FongRuth"}, {"prenom": "Samuel", "nom": "Carton", "name": "CartonSamuel"}, {"prenom": "Tulio", "nom": "Ribeiro", "name": "RibeiroTulio"}, {"prenom": "Regina", "nom": "Barzilay", "name": "BarzilayRegina"}, {"prenom": "Anirudh", "nom": "Rathore", "name": "RathoreAnirudh"}, {"prenom": "Mandela", "nom": "Patrick", "name": "PatrickMandela"}, {"prenom": "Sameer", "nom": "Singh", "name": "SinghSameer"}, {"prenom": "Jasmijn", "nom": "Bastings", "name": "BastingsJasmijn"}, {"prenom": "Wilker", "nom": "Aziz", "name": "AzizWilker"}, {"prenom": "Ivan", "nom": "Titov", "name": "TitovIvan"}, {"prenom": "Ben", "nom": "Poole", "name": "PooleBen"}, {"prenom": "Eric", "nom": "Jang", "name": "JangEric"}, {"prenom": "Francesca", "nom": "Toni"}, {"prenom": "Christopher", "nom": "Potts."}, {"prenom": "Eric", "nom": "Lehman"}, {"prenom": "James", "nom": "Glass"}, {"prenom": "Worker Study", "nom": "Interface"}, {"prenom": "Details", "nom": "Training"}, {"prenom": "Setups No Sufficiency No Continuity No Sparsity", "nom": "No"}, {"prenom": "Mingye", "nom": "Gao"}, {"prenom": "No firstname", "nom": "Stockholm"}, {"prenom": "No firstname", "nom": "Chuang"}, {"prenom": "Piyawat", "nom": "Lertvittayakumjorn"}, {"prenom": "Ivan", "nom": "Titov."}, {"prenom": "No firstname", "nom": "Model"}, {"prenom": "Subset Sampling", "nom": "Process"}, {"prenom": "Model", "nom": "Components"}, {"prenom": "Data", "nom": "Mining"}, {"prenom": "Yulia", "nom": "Tsvetkov."}, {"prenom": "Virtual", "nom": "Event"}, {"prenom": "Jianbo", "nom": "Chen"}, {"prenom": "Random Baselines", "nom": "Human"}, {"prenom": "Worker", "nom": "Group"}, {"prenom": "Punta", "nom": "Cana"}, {"prenom": "No firstname", "nom": "Annual"}, {"prenom": "Caiming", "nom": "Xiong"}, {"prenom": "Luke", "nom": "Zettlemoyer."}, {"prenom": "Hua", "nom": "Shen"}, {"prenom": "Byron C.", "nom": "Wallace."}, {"prenom": "Alex", "nom": "Perelygin"}, {"prenom": "No firstname", "nom": "Jain"}, {"prenom": "Human", "nom": "Computation"}, {"prenom": "Rensis", "nom": "Likert"}, {"prenom": "Shixiang", "nom": "Gu"}, {"prenom": "Eduard H", "nom": "Hovy"}, {"prenom": "Jason", "nom": "Eisner"}, {"prenom": "Andrea", "nom": "Vedaldi."}, {"prenom": "No firstname", "nom": "Lee"}, {"prenom": "User", "nom": "Interface"}, {"prenom": "Jean", "nom": "Wu"}, {"prenom": "Andrew", "nom": "Ng"}, {"prenom": "Tommi", "nom": "S."}, {"prenom": "Yulia", "nom": "Tsvetkov"}, {"prenom": "Christopher", "nom": "Potts"}, {"prenom": "Sparse", "nom": "IB"}, {"prenom": "Movie", "nom": "Review"}, {"prenom": "Jason", "nom": "Eisner."}, {"prenom": "Francesca", "nom": "Toni."}, {"prenom": "Online", "nom": "Abuse"}, {"prenom": "No firstname", "nom": "Hannaneh"}, {"prenom": "Eric", "nom": "Jang"}, {"prenom": "Michael I.", "nom": "Jordan."}, {"prenom": "Sarthak", "nom": "Jain"}, {"prenom": "Vidhisha", "nom": "Balachandran"}, {"prenom": "Jay", "nom": "DeYoung"}, {"prenom": "No firstname", "nom": "Huang"}, {"prenom": "Omar", "nom": "Zaidan"}, {"prenom": "Ben", "nom": "Poole."}, {"prenom": "No firstname", "nom": "Jang"}, {"prenom": "Nazneen Fatema", "nom": "Rajani"}, {"prenom": "Norm", "nom": "Minimization"}, {"prenom": "No firstname", "nom": "Wilker"}, {"prenom": "Le", "nom": "Song"}, {"prenom": "Yuval", "nom": "Pinter"}, {"prenom": "Richard", "nom": "Socher"}, {"prenom": "Dheeraj", "nom": "Rajagopal"}, {"prenom": "Jason", "nom": "Chuang"}, {"prenom": "Mo", "nom": "Yu"}, {"prenom": "Sarah", "nom": "Wiegreffe"}, {"prenom": "Hongyin", "nom": "Luo"}], "url_in_text": ["washington.edu", "https://github.com/", "OpenReview.net"], "doi_in_text": []}